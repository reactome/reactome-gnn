{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdaca7d7",
   "metadata": {},
   "source": [
    "# Reactome_GNN Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30571e-2ba8-45d8-b574-292932741f24",
   "metadata": {},
   "source": [
    "This notebook shows how to obtain GNN-generated embeddings for nodes in the human pathway network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb67d38-533e-47ab-a913-9d235235d68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import dgl\n",
    "from reactome_gnn import utils, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8652ad38-cdf4-43f4-86f3-db4ea8d81500",
   "metadata": {},
   "source": [
    "## Embeddings of a single graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd70dcc7-4625-4088-a63b-045f8f6e5383",
   "metadata": {},
   "source": [
    "Specify the list of markers and the threshold p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0507ada3-c0c0-4186-a30c-10fc31d3182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['RAS', 'MAP', 'IL10', 'EGF', 'EGFR', 'STAT']\n",
    "p_value = 0.05\n",
    "study = 'demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f8244-ebe7-4af2-ab03-8afa07bfe4d5",
   "metadata": {},
   "source": [
    "Create network from the markers and with specified p-value threshold, given the name of the study. This function first runs the enrichment analysis on the human pathway network and returns the significant nodes. This information is then used to create the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "272a3ac7-c72d-432d-b4b2-0fb49aa0c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = utils.create_network_from_markers(markers, p_value, study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea89f1-a0c0-4a25-bb42-9f17e27002da",
   "metadata": {},
   "source": [
    "The main class attribute of the returned graph is `graph.graph_nx` which is a `NetworkX.DiGraph` object---a directed graph where each node has a weight and a significance. Weight is the p-value returned by the enrichment analysis, and significance is a string stating whether the pathway in the network is significant or not. Significant pathways are those that have p-value lower than the specified threshold, in this case 0.05.\n",
    "\n",
    "For example, let's take a look at the nodes corresponding to R-HSA-1358803 and R-HSA-15869 pathways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb5e873-1976-46aa-a28b-22339d2c349b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stId': 'R-HSA-1358803',\n",
       " 'name': 'Downregulation of ERBB2:ERBB3 signaling',\n",
       " 'weight': 0.0109,\n",
       " 'significance': 'significant'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.graph_nx.nodes['R-HSA-1358803']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196b4ec1-6fba-4625-947b-27c9b094a738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stId': 'R-HSA-15869',\n",
       " 'name': 'Metabolism of nucleotides',\n",
       " 'weight': 0.161,\n",
       " 'significance': 'non-significant'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.graph_nx.nodes['R-HSA-15869']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01029b22-eac4-4d6e-8715-413df3ec93b8",
   "metadata": {},
   "source": [
    "We notice that R-HSA-1358803 corresponds to \"Downregulation of ERBB2:ERBB3 signaling\", and is significant in the network created with the markers specified above (its p-value is 0.0109 which is less than 0.05). On the other hand, R-HSA-15869 corresponds to \"Metabolism of nucleotides\" which is non-significant in this network (its p-value is 0.161)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63329ae-4520-4a50-9abe-b00fbe27e840",
   "metadata": {},
   "source": [
    "Next we want to do is create an embedding of that graph. But in order to do that, graph should be in the DGL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47e9b02-64c3-4d4c-bcbb-c0c42f1db087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=16050, num_edges=16850,\n",
       "      ndata_schemes={'weight': Scheme(shape=(), dtype=torch.float32), 'significance': Scheme(shape=(), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_dgl = utils.nx_to_dgl(graph.graph_nx)\n",
    "graph_dgl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998e365-62bc-4a61-9707-5794d01aa556",
   "metadata": {},
   "source": [
    "We also need a GNN model which will produce the embeddings. Since we want the model to be reusable at any given time, the parameters of the model have to be saved to the disk and loaded upon model initialization. The demo model that is already saved is a two-layers Graph Convolutional Network (GCN) and creates the the embeddings with latent dimension of 8.\n",
    "\n",
    "The GCN is chosen because it is a relatively \"lightweight\" model that was proven to have good performance on various graph-related tasks. For example, even when comparing an untrained GCN network against DeepWalk on semi-supervised node classification task, untrained GCN had superior performance! This means that it can more successfully leverage the topology of a graph and create meaningful representation than the traditional methods.\n",
    "\n",
    "First let's use a pretrained model which is saved as `data/example/models/model.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "578d74f1-63f9-4113-a865-0ef0bcb7c38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNModel(\n",
      "  (linear): Linear(in_features=1, out_features=8, bias=True)\n",
      "  (conv_0): GraphConv(in=8, out=8, normalization=both, activation=None)\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (layers): ModuleList()\n",
      "  (predict): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = model.GCNModel(dim_latent=8, num_layers=1)\n",
    "net.load_state_dict(torch.load('data/example/models/model.pth'))\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ae79414-2c92-475d-9312-6923dfb4de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16050, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "        [ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "        [ 0.5390, -1.7577,  3.5163,  ...,  0.0483,  1.2612,  2.4266],\n",
       "        ...,\n",
       "        [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631],\n",
       "        [ 0.6792, -2.1391,  4.2769,  ...,  0.0371,  1.5118,  2.9374],\n",
       "        [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = net(graph_dgl).detach()\n",
    "print(embeddings.shape)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca51a08-bdfe-47a1-9977-85539559d851",
   "metadata": {},
   "source": [
    "This tensor has a shape 16050 x 8, which means that each row represents the embedding of one node, as there are 16050 nodes in the pathway network, and each of these embeddings is 8-dimensional (as specified when initializing the model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ed106-e22c-4930-8d00-eb56f59fb23e",
   "metadata": {},
   "source": [
    "To find the embeddings of some specific pathways, e.g. R-HSA-1358803, we have to load some auxilary information. We can also fetch embeddings of pathways by specifying their name, not only stId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ac3033b-8d36-41c8-87c6-3ede4d6c1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_id = pickle.load(open('data/example/info/name_to_id.pkl', 'rb'))\n",
    "sorted_stid_list = pickle.load(open('data/example/info/sorted_stid_list.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d593d8-048c-4855-9bb4-e5d3a8db4271",
   "metadata": {},
   "source": [
    "Here, `name_to_id` is a dictionary which maps each pathway name to its stId, and sorted_stid_list is, as the name states, the sorted list of all the stIds in the network. This is necessary due to how DGL stores the nodes when converting the network from the NetworkX format. Let's first obtain the embedding of R-HSA-1358803:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c20da87-392a-4f35-9869-e5b2b8dd8dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1191, -0.7060,  1.0289,  0.1243, -0.6507,  0.2316,  0.7704,  0.7426])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = sorted_stid_list.index('R-HSA-1358803')\n",
    "embeddings[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2aa1d-6b62-4ffd-a80c-fab33e482874",
   "metadata": {},
   "source": [
    "Let's now get the embedding of the pathway \"Metabolism of nucleotides\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f949f91c-44eb-41e8-a03a-432aa41a8a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1903, -0.8606,  1.5054,  0.1874, -0.8670,  0.1614,  0.7858,  1.0684])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stid = name_to_id['Metabolism of nucleotides']\n",
    "idx = sorted_stid_list.index(stid)\n",
    "embeddings[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c38020b-6748-4cb4-810c-f2598e4e837a",
   "metadata": {},
   "source": [
    "## Working with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320242ea-919d-41be-a98a-2a695ab32b91",
   "metadata": {},
   "source": [
    "Steps above are useful when we are working with a single pathway network, but the procedure could be cumbersome when we need to work with several networks. That's where we can use datasets to automate part of the process. Here we will work with a toy dataset consisting of four different pathways, generated by lighting up pathways specified via their name. The networks are called A, B, C, and D, and the relations between them is such that $A = D$, $A \\& D \\subset C$, $B \\cap C = \\emptyset$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "205dcc46-a8a7-469a-be36-a6c387237832",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_A, graph_B, graph_c, graph_D, _ = utils.create_toy_study_with_names(data_dir='data/example')\n",
    "embedding_dict = utils.create_embeddings(data_dir='data/example')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d25ee-bb1c-488b-aac0-af45ffdadafe",
   "metadata": {},
   "source": [
    "What happens under the hood is that a PathwayDataset is created. This is a DGL dataset that makes processing raw graphs and loading DGL graphs easier. Creating this dataset is not mandatory, but helps when working with multiple graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d95c12af-8581-4a29-a130-d06657f33ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study_A.dgl\n",
      "Graph(num_nodes=16050, num_edges=16850,\n",
      "      ndata_schemes={'significance': Scheme(shape=(), dtype=torch.float32), 'weight': Scheme(shape=(), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "from reactome_gnn import dataset\n",
    "\n",
    "ds = dataset.PathwayDataset(root='data/example')\n",
    "\n",
    "graph, name = ds[0]\n",
    "print(name)\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2755420-0736-45d7-bcf2-e24f8a0fb47e",
   "metadata": {},
   "source": [
    "But let's return to creating the embeddings. What's inside the embedding_dict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fef9f1f5-7def-41c7-9929-0a44b00aaf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_A.dgl': tensor([[ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "         [ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "         [ 0.5390, -1.7577,  3.5163,  ...,  0.0483,  1.2612,  2.4266],\n",
       "         ...,\n",
       "         [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631],\n",
       "         [ 0.6792, -2.1391,  4.2769,  ...,  0.0371,  1.5118,  2.9374],\n",
       "         [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631]]),\n",
       " 'study_B.dgl': tensor([[ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "         [ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "         [ 0.5390, -1.7577,  3.5163,  ...,  0.0483,  1.2612,  2.4266],\n",
       "         ...,\n",
       "         [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631],\n",
       "         [ 0.6792, -2.1391,  4.2769,  ...,  0.0371,  1.5118,  2.9374],\n",
       "         [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631]]),\n",
       " 'study_C.dgl': tensor([[ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "         [ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "         [ 0.5390, -1.7577,  3.5163,  ...,  0.0483,  1.2612,  2.4266],\n",
       "         ...,\n",
       "         [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631],\n",
       "         [ 0.6792, -2.1391,  4.2769,  ...,  0.0371,  1.5118,  2.9374],\n",
       "         [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631]]),\n",
       " 'study_D.dgl': tensor([[ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "         [ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "         [ 0.5390, -1.7577,  3.5163,  ...,  0.0483,  1.2612,  2.4266],\n",
       "         ...,\n",
       "         [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631],\n",
       "         [ 0.6792, -2.1391,  4.2769,  ...,  0.0371,  1.5118,  2.9374],\n",
       "         [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631]]),\n",
       " 'study_E.dgl': tensor([[ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "         [ 0.5248, -1.7190,  3.4393,  ...,  0.0494,  1.2359,  2.3749],\n",
       "         [ 0.5390, -1.7577,  3.5163,  ...,  0.0483,  1.2612,  2.4266],\n",
       "         ...,\n",
       "         [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631],\n",
       "         [ 0.6792, -2.1391,  4.2769,  ...,  0.0371,  1.5118,  2.9374],\n",
       "         [ 0.6588, -2.0835,  4.1661,  ...,  0.0388,  1.4753,  2.8631]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca468a7b-8e96-43b8-854e-7e494762b9bf",
   "metadata": {},
   "source": [
    "We see that we have obtained a dictionary, where keys are the names of the graphs, and the values are the embedding tensors for the corresponding graphs. The graph E is created for the validation purposes during the model training. We can obtain the embedding of each node in the same way as we did above, in the case of a single graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac737fb8-e99c-4277-95e1-30d4d8e4cd41",
   "metadata": {},
   "source": [
    "### Comparing the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c98590-e589-4167-835e-f9a8ded98037",
   "metadata": {},
   "source": [
    "To compare the embeddings obtained above, we use Canonical Correlation Analysis (CCA).  First we specify the targets Y for each graph, which specify which nodes are significant and which are not. Then we fit the data on the CCA model from scikit-learn. This fitted model can be used to transform embedding data and compare embeddings of nodes across different graphs. This is all done inside the `utils.fit_cca_on_toy_data()` function, so we can simply call it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f79d6668-92c3-46d1-af46-5039d1953f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cca = utils.fit_cca_on_toy_data('data/example')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2294fd-b3a3-4611-92b7-d4bea407657b",
   "metadata": {},
   "source": [
    "But for the sake of ilustration, we show here how it is done step-by-step so that the code can be reused with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6867c7a4-3abf-4514-b569-40d75ee650b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CCA(n_components=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: We do not fit graph D, since it is equivalent to graph A\n",
    "\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "study_A = [\"Signaling by WNT\", \"WNT ligand biogenesis and trafficking\", \"Degradation of beta-catenin by the destruction complex\",\n",
    "           \"TCF dependent signaling in response to WNT\", \"Beta-catenin independent WNT signaling\"]\n",
    "study_B = [\"Autophagy\", \"Macroautophagy\", \"Chaperone Mediated Autophagy\", \"Late endosomal microautophagy\"]\n",
    "study_C = [\"Signal Transduction\", \"Signaling by NOTCH\", \"Signaling by NOTCH1\", \"Signaling by NOTCH2\", \"Signaling by NOTCH3\",\n",
    "           \"Signaling by NOTCH4\", \"Activated NOTCH1 Transmits Signal to the Nucleus\",\n",
    "           \"NOTCH1 Intracellular Domain Regulates Transcription\", \"Signaling by WNT\", \"WNT ligand biogenesis and trafficking\",\n",
    "           \"Degradation of beta-catenin by the destruction complex\", \"TCF dependent signaling in response to WNT\",\n",
    "           \"Beta-catenin independent WNT signaling\"]\n",
    "\n",
    "emb_A = embedding_dict['study_A.dgl']\n",
    "emb_B = embedding_dict['study_B.dgl']\n",
    "emb_C = embedding_dict['study_C.dgl']\n",
    "emb_D = embedding_dict['study_D.dgl']\n",
    "\n",
    "name_to_id = pickle.load(open('data/example/info/name_to_id.pkl', 'rb'))\n",
    "sorted_stid_list = pickle.load(open('data/example/info/sorted_stid_list.pkl', 'rb'))\n",
    "\n",
    "indices_A = [sorted_stid_list.index(id) for name, id in name_to_id.items() if name in study_A]\n",
    "indices_B = [sorted_stid_list.index(id) for name, id in name_to_id.items() if name in study_B]\n",
    "indices_C = [sorted_stid_list.index(id) for name, id in name_to_id.items() if name in study_C]\n",
    "\n",
    "y_A = torch.tensor([1.0 if i in indices_A else 0.0 for i in range(len(sorted_stid_list))]).unsqueeze(-1)\n",
    "y_B = torch.tensor([1.0 if i in indices_B else 0.0 for i in range(len(sorted_stid_list))]).unsqueeze(-1)\n",
    "y_C = torch.tensor([1.0 if i in indices_C else 0.0 for i in range(len(sorted_stid_list))]).unsqueeze(-1)\n",
    "\n",
    "cca = CCA(1)\n",
    "cca.fit(emb_A, y_A).fit(emb_B, y_B).fit(emb_C, y_C)\n",
    "cca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b821c912-a762-43ed-b151-965e8336e465",
   "metadata": {},
   "source": [
    "Next thing we need to do is transform the embedding tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "719a2de2-ff7a-45fd-8bfc-b09f6d1892ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_A_t = cca.transform(emb_A)\n",
    "emb_B_t = cca.transform(emb_B)\n",
    "emb_C_t = cca.transform(emb_C)\n",
    "emb_D_t = cca.transform(emb_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8157b-2241-4710-b93e-6bac78d5c430",
   "metadata": {},
   "source": [
    "Finally, we can compare the obtained embeddings. For example, let's compare the embeddings of nodes that correspond to pathway \"WNT ligand biogenesis and trafficking\". This pathway is present in graphs A, C, and D, but not in B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6064930-1034-40d1-8443-9fb2fe1e0ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00035058] [-9.12171039e-07] [0.00035058] [0.00035058]\n"
     ]
    }
   ],
   "source": [
    "stid = name_to_id['WNT ligand biogenesis and trafficking']\n",
    "idx = sorted_stid_list.index(stid)\n",
    "\n",
    "print(emb_A_t[idx], emb_B_t[idx], emb_C_t[idx], emb_D_t[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262da5f-9b4b-4c02-8469-c648723e21a3",
   "metadata": {},
   "source": [
    "We can see that the values returned are identical in the case of A and D, as it should be since these networks are the same. We also notice that the values are relatively close to each other in case of A and C (as well as D and C),\n",
    "In fact, we can also see that the value of C is also matching the values of A and D. This is due to similarity of the three pathway networks, and the lack of expressive power of the used model---it has only one GCN layer. Finally, we notice that the value is significantly different in the case of network B in which this pathway is not significant. This shows that the embeddings are consistent within this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418858a3-1cab-438f-9ccf-1c85ce366bfa",
   "metadata": {},
   "source": [
    "## Training a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f861195-fc6f-4fd0-af6c-60f7eff26b0d",
   "metadata": {},
   "source": [
    "Let's now train a new model from scratch! First we need to define hyperparameters which will be used. The available hyperparameters are:\n",
    "- `num_epochs` - For how many epochs will the model be trained\n",
    "- `dim_latent` - Dimension of the produced embeddings\n",
    "- `num_layers` - Number of hidden GCN layers in the network\n",
    "- `batch_size` - Number of examples in a mini-batch\n",
    "- `device`     - CUDA or CPU\n",
    "- `lr`         - Learning rate\n",
    "\n",
    "The hyperparameters are stored in a dictionary. Let's define a network with 4 GCN layers, and let the embedding dimenion be 4. We will train the network for 100 epochs. The batch size, due to a small number of training dataset, will be one, and learning rate will be 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78a6f931-e585-4b7a-a84e-5ac970499eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        'num_epochs': 100,\n",
    "        'dim_latent': 4,\n",
    "        'num_layers': 4,\n",
    "        'batch_size': 1,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'lr': 1e-3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ba9a5-570d-402b-bf99-60284e327558",
   "metadata": {},
   "source": [
    "Training the model can be done separately by calling a `train` function in the `train.py` module. The loss plot will be saved to the disk, as well as the trained model. However, this is also done automatically in the `utils.create_embeddings` function, if appropriate arguments are passed. We can take a look at that function to see which arguments we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed48f976-9872-4d5c-9e7d-c9f6b2ea977f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_embeddings in module reactome_gnn.utils:\n",
      "\n",
      "create_embeddings(load_model=True, save=False, data_dir='demo/data/example', hyperparams=None, plot=True)\n",
      "    Create embeddings for all the graphs stored on the disk.\n",
      "    \n",
      "    First the Pathway dataset is created which takes all the graphs\n",
      "    stored in the 'raw' directory, processes them, and stores them in\n",
      "    the 'processed' directory. Each graph is fed to the model with\n",
      "    specified latent dimension and number of GCN layers, which returns\n",
      "    the embedding of that graph. All the embeddings are saved on the\n",
      "    disk in the 'embeddings' directory.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    load_model : bool, optional\n",
      "        Whether to load an old model or create a new one\n",
      "    save : bool, optional\n",
      "        Whether to save the created embeddings to the disk, default: False\n",
      "    data_dir : str, optional\n",
      "        Relative path to where the data is stored\n",
      "    hyperparams : dict, optional\n",
      "        In case no hyperparameter dictionary is passed, default\n",
      "        hyperparameters are used\n",
      "    plot : bool, optional\n",
      "        In case of training the model, whether loss should be plotted\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    list\n",
      "        A list of embedding-tuples, the first element in the tuple is\n",
      "        the name of the graph, the second element is the corresponding\n",
      "        embedding.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(utils.create_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e2263d-5280-46f6-8489-d4a906a3bb2b",
   "metadata": {},
   "source": [
    "We can see that `load_model` should be set to `False` (since we want to train a new model, not load a pretrained one), and that we should pass the defined dictionary as `hyperparams`. Running this function will also run the training loop, which will output training and validation loss every 10 epochs, as well as plot the graph of how loss changes over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa766c01-853f-4224-9b6a-651c7b521449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\t\tTraining loss: 0.501051127910614\n",
      "Epoch: 10\t\tValidation loss: 0.49857112765312195\n",
      "Epoch: 20\t\tTraining loss: 0.4540109535058339\n",
      "Epoch: 20\t\tValidation loss: 0.44984833896160126\n",
      "Epoch: 30\t\tTraining loss: 0.37716904282569885\n",
      "Epoch: 30\t\tValidation loss: 0.37077496945858\n",
      "Epoch: 40\t\tTraining loss: 0.2716922660668691\n",
      "Epoch: 40\t\tValidation loss: 0.2640504986047745\n",
      "Epoch: 50\t\tTraining loss: 0.16615507503350577\n",
      "Epoch: 50\t\tValidation loss: 0.1598590463399887\n",
      "Epoch: 60\t\tTraining loss: 0.09329420328140259\n",
      "Epoch: 60\t\tValidation loss: 0.0896369069814682\n",
      "Epoch: 70\t\tTraining loss: 0.05581085259715716\n",
      "Epoch: 70\t\tValidation loss: 0.05398019589483738\n",
      "Epoch: 80\t\tTraining loss: 0.037939353535572685\n",
      "Epoch: 80\t\tValidation loss: 0.03694095276296139\n",
      "Epoch: 90\t\tTraining loss: 0.028637549529472988\n",
      "Epoch: 90\t\tValidation loss: 0.027999610640108585\n",
      "Epoch: 100\t\tTraining loss: 0.02316673845052719\n",
      "Epoch: 100\t\tValidation loss: 0.022698458284139633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dict = utils.create_embeddings(data_dir='data/example', load_model=False, hyperparams=hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c0e12-8161-43f3-a1b3-d052eb1a0b80",
   "metadata": {},
   "source": [
    "We can notice how the loss drops significantly during training.\n",
    "\n",
    "Since these embeddings are not stored on the disk (we didn't specify `save=True`), let's perform CCA analysis manually once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d353cafd-60db-4231-8900-762d1a64bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_A = embedding_dict['study_A.dgl']\n",
    "emb_B = embedding_dict['study_B.dgl']\n",
    "emb_C = embedding_dict['study_C.dgl']\n",
    "emb_D = embedding_dict['study_D.dgl']\n",
    "\n",
    "name_to_id = pickle.load(open('data/example/info/name_to_id.pkl', 'rb'))\n",
    "sorted_stid_list = pickle.load(open('data/example/info/sorted_stid_list.pkl', 'rb'))\n",
    "\n",
    "indices_A = [sorted_stid_list.index(id) for name, id in name_to_id.items() if name in study_A]\n",
    "indices_B = [sorted_stid_list.index(id) for name, id in name_to_id.items() if name in study_B]\n",
    "indices_C = [sorted_stid_list.index(id) for name, id in name_to_id.items() if name in study_C]\n",
    "\n",
    "y_A = torch.tensor([1.0 if i in indices_A else 0.0 for i in range(len(sorted_stid_list))]).unsqueeze(-1)\n",
    "y_B = torch.tensor([1.0 if i in indices_B else 0.0 for i in range(len(sorted_stid_list))]).unsqueeze(-1)\n",
    "y_C = torch.tensor([1.0 if i in indices_C else 0.0 for i in range(len(sorted_stid_list))]).unsqueeze(-1)\n",
    "\n",
    "cca = CCA(1)\n",
    "cca.fit(emb_A, y_A).fit(emb_B, y_B).fit(emb_C, y_C)\n",
    "\n",
    "emb_A_t = cca.transform(emb_A)\n",
    "emb_B_t = cca.transform(emb_B)\n",
    "emb_C_t = cca.transform(emb_C)\n",
    "emb_D_t = cca.transform(emb_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a80e186-fe6d-4e2b-bf0e-e95f9076e0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00024677] [7.02518821e-05] [0.0003934] [0.00024677]\n"
     ]
    }
   ],
   "source": [
    "stid = name_to_id['WNT ligand biogenesis and trafficking']\n",
    "idx = sorted_stid_list.index(stid)\n",
    "\n",
    "print(emb_A_t[idx], emb_B_t[idx], emb_C_t[idx], emb_D_t[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd6a71-f50c-4c4e-a58f-2673d1316f8c",
   "metadata": {},
   "source": [
    "We see that the values of A and D are still the same as they should be. The value of C now differs from the value of A and D, although it's still relatively close to them. This is due to the fact that this network has a lot better expressivity than the one in the previous case (pretrained network). Here we used 4 GCN layers, meaning that a lot of information about the neighborhood will be condensed into a single node. From this we can conclude that the embeddings are still consistent within this dataset, but also that larger number of layers doesn't necessarily lead to better embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
